from confluent_kafka import Consumer
from confluent_kafka.schema_registry import SchemaRegistryClient
from confluent_kafka.schema_registry.avro import AvroDeserializer
from confluent_kafka.serialization import SerializationContext, MessageField
import psycopg2
import socket
import json
import time
import sys

# ğŸ”¹ ConfiguraciÃ³n de conexiÃ³n a PostgreSQL
DB_CONFIG = {
    "dbname": "sensores_db",
    "user": "sensor_user",
    "password": "sensor_password",
    "host": "localhost",
    "port": "5432"
}

# ğŸ”¹ FunciÃ³n para insertar datos en PostgreSQL
def insert_data(cursor, sensor_id, timestamp, temperatura, humedad, presion):
    cursor.execute(
        """
        INSERT INTO sensores (sensor_id, timestamp, temperatura, humedad, presion)
        VALUES (%s, to_timestamp(%s), %s, %s, %s)
        """,
        (sensor_id, timestamp, temperatura, humedad, presion)
    )

# ğŸ”¹ DetecciÃ³n automÃ¡tica del entorno (Docker o mÃ¡quina local)
def get_kafka_broker():
    try:
        socket.gethostbyname("broker")  # Si "broker" se resuelve, estamos en Docker
        return "broker:29092"
    except socket.gaierror:
        return "localhost:9092"

KAFKA_BROKER = get_kafka_broker()
SCHEMA_REGISTRY_URL = "http://schema_registry:8081" if KAFKA_BROKER.startswith("broker") else "http://localhost:8081"

print(f"ğŸ“Œ Conectando a Kafka en: {KAFKA_BROKER}")
print(f"ğŸ“Œ Conectando a Schema Registry en: {SCHEMA_REGISTRY_URL}")

# ğŸ”¹ ConexiÃ³n a Schema Registry
schema_registry_conf = {"url": SCHEMA_REGISTRY_URL}
try:
    schema_registry_client = SchemaRegistryClient(schema_registry_conf)
except Exception as e:
    print(f"âŒ Error conectando con Schema Registry: {e}")
    exit(1)

# ğŸ”¹ Esquema Avro (debe coincidir con el `producer.py`)
SCHEMA_STR = """
{
    "type": "record",
    "name": "SensorData",
    "fields": [
        {"name": "sensor_id", "type": "string"},
        {"name": "timestamp", "type": "long"},
        {"name": "temperatura", "type": "float"},
        {"name": "humedad", "type": "float"},
        {"name": "presion", "type": "float"}
    ]
}
"""

avro_deserializer = AvroDeserializer(
    schema_registry_client,
    SCHEMA_STR
)

# ğŸ”¹ ConfiguraciÃ³n del consumidor de Kafka
consumer_conf = {
    "bootstrap.servers": KAFKA_BROKER,
    "group.id": "sensor_consumers",
    "auto.offset.reset": "earliest",  # Leer desde el inicio si no hay offset guardado
}

try:
    consumer = Consumer(consumer_conf)
except Exception as e:
    print(f"âŒ Error conectando con Kafka: {e}")
    exit(1)

# ğŸ”¹ ConexiÃ³n a PostgreSQL (una sola vez, en lugar de por mensaje)
try:
    conn = psycopg2.connect(**DB_CONFIG)
    cursor = conn.cursor()
    print("âœ… Conectado a PostgreSQL correctamente.")
except Exception as e:
    print(f"âŒ Error conectando a PostgreSQL: {e}")
    exit(1)

# ğŸ”¹ Suscribirse al tÃ³pico de Kafka
TOPIC = "sensor_data"
consumer.subscribe([TOPIC])
print(f"ğŸš€ Esperando mensajes en el tÃ³pico: {TOPIC}...\n")

# ğŸ”¹ Procesar mensajes de Kafka en un bucle infinito
try:
    while True:
        msg = consumer.poll(1.0)  # Esperar 1 segundo por un mensaje

        if msg is None:
            continue  # No hay mensajes disponibles

        if msg.error():
            print(f"âŒ Error en el mensaje: {msg.error()}")
            continue

        # ğŸ”¹ Deserializar mensaje Avro
        try:
            compressed_size = len(msg.value())
            print(f"ğŸ“¦ TamaÃ±o del mensaje comprimido: {compressed_size} bytes")

            sensor_data = avro_deserializer(msg.value(), SerializationContext(TOPIC, MessageField.VALUE))
            if not sensor_data:
                print("âš ï¸ Mensaje vacÃ­o recibido.")
                continue
            
            decompressed_size = sys.getsizeof(avro_deserializer)
            print(f"ğŸ“¦ TamaÃ±o del mensaje descomprimido: {decompressed_size} bytes")

            print(f"âœ… Mensaje recibido: {json.dumps(sensor_data, indent=2)}")

            # ğŸ”¹ Intentar insertar datos en PostgreSQL
            try:
                insert_data(
                    cursor,
                    sensor_data["sensor_id"],
                    sensor_data["timestamp"],
                    sensor_data["temperatura"],
                    sensor_data["humedad"],
                    sensor_data["presion"]
                )
                conn.commit()  # ğŸ”¹ Confirmar transacciÃ³n
                print("ğŸ’¾ Datos insertados en PostgreSQL.")

            except psycopg2.Error as e:
                conn.rollback()  # ğŸ”¹ Revertir cambios en caso de error
                print(f"âŒ Error insertando en PostgreSQL: {e}")

        except Exception as e:
            print(f"âŒ Error deserializando mensaje Avro: {e}")

except KeyboardInterrupt:
    print("\nğŸ›‘ Deteniendo el consumidor...")
# icono de disco flexible


finally:
    print("ğŸ”„ Cerrando conexiones...")
    consumer.close()
    cursor.close()
    conn.close()
    print("âœ… Conexiones cerradas correctamente.")
